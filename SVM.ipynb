{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31',\n",
       "       'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41',\n",
       "       'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51',\n",
       "       'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61',\n",
       "       'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"MyNewFile.csv\")\n",
    "type(data)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"Y\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop([\"Y\"],axis=1)\n",
    "#x = (temp-np.min(temp))/(np.max(temp)-np.min(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features set X from the target column (class label) y, \n",
    "# and divide the data set to 80% for training, and 20% for testing:\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, train_size=0.80, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y) ,len(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two objects from SVM, to create two different classifiers; \n",
    "# one with Polynomial kernel, and another one with RBF kernel:\n",
    "\n",
    "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(x_train, y_train)\n",
    "poly = svm.SVC(kernel='poly', degree=3, C=1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the efficiency of the two models, \n",
    "# weâ€™ll test the two classifiers using the test data set:\n",
    "\n",
    "poly_pred = poly.predict(x_test)\n",
    "rbf_pred = rbf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Polynomial Kernel):  62.25\n",
      "F1 (Polynomial Kernel):  47.77\n"
     ]
    }
   ],
   "source": [
    "# calculate the accuracy and f1 scores for SVM with Polynomial kernel:\n",
    "\n",
    "poly_accuracy = accuracy_score(y_test, poly_pred)\n",
    "poly_f1 = f1_score(y_test, poly_pred, average='weighted')\n",
    "print('Accuracy (Polynomial Kernel): ', \"%.2f\" % (poly_accuracy*100))\n",
    "print('F1 (Polynomial Kernel): ', \"%.2f\" % (poly_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (RBF Kernel):  62.25\n",
      "F1 (RBF Kernel):  47.77\n"
     ]
    }
   ],
   "source": [
    "# calculate the accuracy and f1 scores for SVM with RBF kernel:\n",
    "\n",
    "rbf_accuracy = accuracy_score(y_test, rbf_pred)\n",
    "rbf_f1 = f1_score(y_test, rbf_pred, average='weighted')\n",
    "print('Accuracy (RBF Kernel): ', \"%.2f\" % (rbf_accuracy*100))\n",
    "print('F1 (RBF Kernel): ', \"%.2f\" % (rbf_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as num\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "\n",
    "\n",
    "def main():\n",
    "    data = datasets.data()\n",
    "\n",
    "    # Some noisy data not correlated\n",
    "    e = num.random.uniform(0, 0.2, size=(len(data), 30))\n",
    "\n",
    "    x = num.hstack((data, e))\n",
    "    Y = data.target\n",
    "\n",
    "    estimators = linear_model.LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\")\n",
    "\n",
    "    selectors = GeneticSelectionCV(estimators,\n",
    "                                  cv=6,\n",
    "                                  verbose=2,\n",
    "                                  scoring=\"accuracy\",\n",
    "                                  max_features=6,\n",
    "                                  n_population=60,\n",
    "                                  crossover_proba=0.6,\n",
    "                                  mutation_proba=0.2,\n",
    "                                  n_generations=50,\n",
    "                                  crossover_independent_proba=0.6,\n",
    "                                  mutation_independent_proba=0.06,\n",
    "                                  tournament_size=4,\n",
    "                                  n_gen_no_change=20,\n",
    "                                  caching=True,\n",
    "                                  n_jobs=-2)\n",
    "    selectors = selectors.fit(x, Y)\n",
    "\n",
    "    print(selectors.support_)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn_genetic.space import Categorical, Integer, Continuous\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "nsample = len(data.images)\n",
    "x = data.images.reshape((nsample, -1))\n",
    "y = data['target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "\n",
    "_, axes = plot.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for axis, image, label in zip(axes, data.images, data.target):\n",
    "    axis.set_axis_off()\n",
    "    axis.imshow(image, cmap=plot.cm.gray_r, interpolation='nearest')\n",
    "    axis.set_title('Training: %i' % label)\n",
    "    param_grid = {'min_weight_fraction_leaf': Continuous(0.01, 0.5, distribution='log-uniform'),\n",
    "              'bootstrap': Categorical([True, False]),\n",
    "              'max_depth': Integer(2, 30),\n",
    "              'max_leaf_nodes': Integer(2, 35),\n",
    "              'n_estimators': Integer(100, 300)}\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# The main class from sklearn-genetic-opt\n",
    "evolved_estimator = GASearchCV(estimator=classifier,\n",
    "                              cv=cv,\n",
    "                              scoring='accuracy',\n",
    "                              param_grid=param_grid,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=True)\n",
    "\n",
    "evolved_estimator.fit(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
